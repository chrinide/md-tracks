#!/usr/bin/python
# MD-Tracks is a statistical analysis toolkit for molecular dynamics
# and monte carlo simulations.
# Copyright (C) 2007 - 2009 Toon Verstraelen <Toon.Verstraelen@UGent.be>, Center
# for Molecular Modeling (CMM), Ghent University, Ghent, Belgium; all rights
# reserved unless otherwise stated.
#
# This file is part of MD-Tracks.
#
# MD-Tracks is free software; you can redistribute it and/or
# modify it under the terms of the GNU General Public License
# as published by the Free Software Foundation; either version 3
# of the License, or (at your option) any later version.
#
# In addition to the regulations of the GNU General Public License,
# publications and communications based in parts on this program or on
# parts of this program are required to cite the following article:
#
# "MD-TRACKS: A productive solution for the advanced analysis of Molecular
# Dynamics and Monte Carlo simulations", Toon Verstraelen, Marc Van Houteghem,
# Veronique Van Speybroeck and Michel Waroquier, Journal of Chemical Information
# and Modeling, 48 (12), 2414-2424, 2008
# DOI:10.1021/ci800233y
#
# MD-Tracks is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with this program; if not, see <http://www.gnu.org/licenses/>
#
# --


from tracks.core import load_track, dump_track, MultiTracksReader, MultiTracksWriter
from tracks.parse import parse_slice, iter_unit_cells
from tracks.optparse import add_quiet_option, add_slice_option
from tracks.log import log, usage_tail

from molmod.units import parse_unit
from molmod.unit_cell import UnitCell

import numpy, itertools
from optparse import OptionParser


usage = """%prog [options] prefix_a0 [prefix_a1 ...] [- prefix_b1 [prefix_b2 ...]] cell rmax nbins output_prefix

%prog generates a histogram of the radial distribution function. A first group
of prefixes defines the Cartesian coordinates to be used. Optionally a second
group of Cartesian coordinates can be defined. The two groups are separated by
a minus sign. If only one group is given, the rdf is computed based on the
distances between the coordinates in this group. If a second group is given,
the distances between the coordinates of both groups are considered. For each
prefix, it is assumed that three files exist: ${prefix}.x, ${prefix}.y and
${prefix}.z. If only one group is defined, at least two prefixes must be given.

The last four arguments have the following interpretation:

* cell: The unit cell parameters. Several formats are supported:
    - a,: A cubic unit cell with ridge a.
    - a,b,c: The parameters of an orthorhombic cell.
    - a,b,c,alpha,beta,gamma: The parameters for a triclinic cell.
    - ax,ay,az,bx,by,bz,cx,cy,cz: The cartesian parameters for a triclinic cell.
    - cell_prefix: A track prefix can be used for a time dependent unit cell.
    (The presence of comma's is used to differentiate between all the possibilities.)
* rmax: The maximum (inter-atomic) distance for which the rdf is computed.
* nbins: The number of bins in the histogram. (including the empty ones)
* output_prefix: The prefix used for all the output files.

In the standard operation mode, two files are generated:

* ${output_prefix}.bins: A track with the bin-centers
* ${output_prefix}.hist: A track with the y-values of the rdf

If the option --bin-tracks is used, the last file is not generated, but instead
a series of files ${output_prefix}.bin.${bin_index} are created. Each file is a
track with the time-dependent number of counts in each corresponding bin. This
data can be used to compute a correct statistical error on the rdf with tr-blav.
""" + usage_tail

parser = OptionParser(usage)
add_slice_option(parser)
add_quiet_option(parser)
parser.add_option(
    "--bin-tracks", action="store_true", default=False,
    help="Create a separate track for each bin, to be processed with tr-blav."
)
parser.add_option(
    "-p", "--plain", dest="normalize", action="store_false", default=True,
    help="Make plain distribution, i.e. do not divide the histogram by the "
         "ideal gas probability.",
)
(options, args) = parser.parse_args()


log.verbose = options.verbose
if len(args) >= 6:
    unit_cell_str = args[-4]
    rmax = parse_unit(args[-3])
    nbins = int(args[-2])
    output_prefix = args[-1]
    if nbins < 2:
        parser.error("Expecting at least two bins.")
    prefixes_str = " ".join(args[:-4])
    minus_count = prefixes_str.count(" - ")
    if minus_count == 1:
        prefixes_a, prefixes_b = prefixes_str.split(" - ")
        prefixes_a = prefixes_a.split()
        prefixes_b = prefixes_b.split()
    elif  minus_count == 0:
        prefixes_a = prefixes_str.split(" ")
        prefixes_b = None
    else:
        parser.error("At most two groups of prefixes are allowed, separated by a minus sign. Got %i" % minus_count)
else:
    parser.error("Expecting at least six arguments.")

sub = parse_slice(options.slice)
bin_width = rmax/nbins
bins = numpy.arange(nbins)*bin_width + bin_width*0.5
radii = numpy.arange(nbins)*bin_width
filename = "%s.bins" % output_prefix
dump_track("%s.bins" % output_prefix, bins)
log("WRITTEN %s" % filename)

# the number of particles:
if prefixes_b is None:
    N = len(prefixes_a)
    correction = float(N)/(0.5*N*(N-1))
else:
    N = len(prefixes_b)
    correction = 1/float(len(prefixes_a))


def iter_deltas():
    if prefixes_b is None:
        filenames = sum([["%s.x" % prefix_a, "%s.y" % prefix_a, "%s.z" % prefix_a] for prefix_a in prefixes_a], [])
        num_a = len(prefixes_a)
        dtype = numpy.dtype([("cor", float, (num_a, 3))])
        mtr = MultiTracksReader(filenames, dtype, sub=sub)
        num_deltas = (num_a*(num_a-1))/2
        deltas = numpy.zeros((num_deltas,3),float)
        for row in mtr:
            counter = 0
            coordinates = row["cor"]
            for i in xrange(len(coordinates)):
                for j in xrange(i):
                    deltas[counter]=coordinates[i]-coordinates[j]
                    counter += 1
            yield deltas
    else:
        filenames = sum([["%s.x" % prefix, "%s.y" % prefix, "%s.z" % prefix] for prefix in (prefixes_a + prefixes_b)], [])
        num_a = len(prefixes_a)
        num_b = len(prefixes_b)
        dtype = numpy.dtype([("a", float, (num_a, 3)), ("b", float, (num_b, 3))])
        mtr = MultiTracksReader(filenames, dtype, sub=sub)
        num_deltas = num_a*num_b
        deltas = numpy.zeros((num_deltas,3),float)
        for row in mtr:
            counter = 0
            coordinates_a = row["a"]
            coordinates_b = row["b"]
            for i in xrange(num_a):
                for j in xrange(num_b):
                    deltas[counter]=coordinates_a[i]-coordinates_b[j]
                    counter += 1
            yield deltas

def iter_distances():
    for uc, deltas in itertools.izip(iter_unit_cells(unit_cell_str, sub), iter_deltas()):
        rho = N/uc.generalized_volume()
        reference_counts = rho*4*numpy.pi/3*((radii+bin_width)**3-radii**3)
        distances = []
        if uc is None:
            distances = numpy.sqrt((numpy.array(deltas)**2).sum(axis=1))
        else:
            deltas = numpy.array([uc.shortest_vector(delta) for delta in deltas])
            for n in uc.get_radius_indexes(rmax):
                distances.append(numpy.sqrt((numpy.array(deltas+numpy.dot(uc.cell, n))**2).sum(axis=1)))
            distances = numpy.concatenate(distances)
        yield distances[distances < rmax], reference_counts

if options.bin_tracks:
    bin_filenames = (
        ["%s.bin.%07i" % (output_prefix, b_index) for b_index in xrange(nbins)] +
        ["%s.cumul.bin.%07i" % (output_prefix, b_index) for b_index in xrange(nbins)]
    )
    dtype = numpy.dtype([("bin", float, nbins),("cumul_bin", float, nbins)])
    mtw = MultiTracksWriter(bin_filenames, dtype)
    for distances, reference_counts in iter_distances():
        if options.normalize:
            counts = correction*numpy.histogram(distances, nbins, (0,rmax), False)[0]
            mtw.dump_row((counts/reference_counts, counts.cumsum()))
        else:
            counts = numpy.histogram(distances, nbins, (0,rmax), False)[0]
            mtw.dump_row((counts, counts.cumsum()))
    mtw.finish()
else:
    counts = 0.0
    row_count = 0
    for distances, reference_counts in iter_distances():
        if options.normalize:
            counts += correction*numpy.histogram(distances, nbins, (0,rmax), False)[0]
        else:
            counts += numpy.histogram(distances, nbins, (0,rmax), False)[0]
        row_count += 1

    filename = "%s.hist" % output_prefix
    if options.normalize:
        dump_track(filename, counts/row_count/reference_counts)
    else:
        dump_track(filename, counts/row_count)
    log("WRITTEN %s" % filename)

    filename = "%s.cumul.hist" % output_prefix
    dump_track(filename, counts.cumsum()/row_count)
    log("WRITTEN %s" % filename)


